{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a language model to predict the next word given the previous N words it is advantageous to use smoothing on the counts you get from the training data to help the model generalize better. Kneser-Ney helps with this in 4 ways:  \n",
    "1. If we come across an unseen example we should backoff to n-1 grams. (e.g., if we are using a bigram model and we come across 'cat', a word we've never seen before, we should back off of our bigram model to a unigram model to try and predict the word that follows 'cat')\n",
    "2. If we back off we should do so \"smoothly\"\n",
    "3. We should reduce our counts slightly, because training data often over estimates the real number of occurrences. (e.g., our training data will estimate that 'great' follows 'today is' 3 times, but given a larger body of text it is most likely less than 3.)\n",
    "4. The fertility of a word is more useful than it's ngram probability (e.g., in an article about San Francisco the unigram Francisco will have a very high probability of being the next word when using a unigram model. This is a gross over estimate and should be corrected by making the probability of each word the number of unique ngrams it completes / total unique ngrams. Once can see how this would drop the probability of Fransisco dramatically)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kneser-Ney Algorithm\n",
    "\n",
    "P(word | previous_n_words) =  \n",
    "[max(number of occurrences that word follows previous n words - sigma, 0) / number of occurrences of previous n words followed by any word]  \n",
    "\n",
    "plus [sigma / number of occurrences of previous n words followed by any word * number of distinct words that follow previous n words]    \n",
    "\n",
    "multiplied by [number of distinct ngrams word completes / number of distinct n grams]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Kneser-Ney we need to define 7 vairables:  \n",
    "1. Our vocabulary of distinct words\n",
    "2. The number of ngrams that each word completes (not distinct)\n",
    "3. The total number of ngrams (not distinct) that start w/previous n words\n",
    "4. The distinct number of ngrams\n",
    "5. The distinct number of ngrams that each word starts\n",
    "5. The distinct number of ngrams that each word complets\n",
    "6. Sigma, the amount of probability we will subtract from each probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create some fake text to apply Kneser-Ney to\n",
    "#I have built in a few things that normal preprocessing would\n",
    "#take care of:\n",
    "#<s> is an indicator of a new sentence\n",
    "#<s/> is an indicator of the end of a sentence\n",
    "#I have made everything lower case\n",
    "text = \"<s> the dog jumped down the stairs <s/> <s> the dog ran down the street <s/> \"\n",
    "\n",
    "#split the text into a list for ease of iterating\n",
    "#to get necessary counts\n",
    "text_split = text.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our vaiables one at a time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Build Distinct Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build vocab of distinct words\n",
    "vocab = []\n",
    "for i in text.split():\n",
    "    if i not in vocab:\n",
    "        vocab.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', 'the', 'dog', 'jumped', 'down', 'stairs', '<s/>', 'ran', 'street']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at vocab\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#length of vocab\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ngrams that each word completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dict to store ngrams\n",
    "#this is not disctinct\n",
    "#key is word that completes ngram\n",
    "#value is dict where key is prior word\n",
    "#and value is number of times word \n",
    "#completes (follows) prior word\n",
    "ngrams_by_word = defaultdict(dict)\n",
    "\n",
    "for idx, item in enumerate(text_split):\n",
    "    if idx == 0:\n",
    "        continue\n",
    "    try:\n",
    "        ngrams_by_word[item][text_split[idx - 1]] += 1 \n",
    "    except KeyError: \n",
    "        ngrams_by_word[item][text_split[idx - 1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(dict,\n",
       "            {'<s/>': {'stairs': 1, 'street': 1},\n",
       "             '<s>': {'<s/>': 1},\n",
       "             'dog': {'the': 2},\n",
       "             'down': {'jumped': 1, 'ran': 1},\n",
       "             'jumped': {'dog': 1},\n",
       "             'ran': {'dog': 1},\n",
       "             'stairs': {'the': 1},\n",
       "             'street': {'the': 1},\n",
       "             'the': {'<s>': 2, 'down': 2}})"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at dict\n",
    "ngrams_by_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The total number of ngrams started by wi-n-1, ..., wi-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_started_by_wi_minus = defaultdict(int)\n",
    "\n",
    "for i,j in enumerate(text_split[-1::-1]):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    ngrams_started_by_wi_minus[j] += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<s/>': 1,\n",
       "             '<s>': 2,\n",
       "             'dog': 2,\n",
       "             'down': 2,\n",
       "             'jumped': 1,\n",
       "             'ran': 1,\n",
       "             'stairs': 1,\n",
       "             'street': 1,\n",
       "             'the': 4})"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_started_by_wi_minus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. The disctinct list of ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create list to store ngrams:\n",
    "distinct_ngrams = []\n",
    "\n",
    "for i,j in enumerate(text_split):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    if (text_split[i-1], j) not in distinct_ngrams:\n",
    "        distinct_ngrams.append((text_split[i-1], j))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('<s>', 'the'),\n",
       " ('the', 'dog'),\n",
       " ('dog', 'jumped'),\n",
       " ('jumped', 'down'),\n",
       " ('down', 'the'),\n",
       " ('the', 'stairs'),\n",
       " ('stairs', '<s/>'),\n",
       " ('<s/>', '<s>'),\n",
       " ('dog', 'ran'),\n",
       " ('ran', 'down'),\n",
       " ('the', 'street'),\n",
       " ('street', '<s/>')]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at list\n",
    "distinct_ngrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5a. The distinct number of ngrams started by each word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_started_by_word = defaultdict(int)\n",
    "\n",
    "for i in vocab:\n",
    "    for j in distinct_ngrams:\n",
    "        if j[0] == i:\n",
    "            ngrams_started_by_word[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<s/>': 1,\n",
       "             '<s>': 1,\n",
       "             'dog': 2,\n",
       "             'down': 1,\n",
       "             'jumped': 1,\n",
       "             'ran': 1,\n",
       "             'stairs': 1,\n",
       "             'street': 1,\n",
       "             'the': 3})"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look\n",
    "ngrams_started_by_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. The distinct number of ngrams each word completes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ngrams_completed_by_word = defaultdict(int)\n",
    "\n",
    "for i in vocab:\n",
    "    for j in distinct_ngrams:\n",
    "        if j[1] == i:\n",
    "            ngrams_completed_by_word[i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'<s/>': 2,\n",
       "             '<s>': 1,\n",
       "             'dog': 1,\n",
       "             'down': 2,\n",
       "             'jumped': 1,\n",
       "             'ran': 1,\n",
       "             'stairs': 1,\n",
       "             'street': 1,\n",
       "             'the': 2})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngrams_completed_by_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this ones easy bc you set it to whatever you want!\n",
    "#value is usually btw 0 - 1\n",
    "sigma = .5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before running the entire smoothin algorithm across all of the text, let's just run it for one point in time and examing the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# partial_text = \"\"\"dog\"\"\"\n",
    "\n",
    "#given dog, for each word in our\n",
    "#vocabular what is probability that it\n",
    "#will follow dog\n",
    "\n",
    "def kneser_ney(partial_text):\n",
    "    #build dict to hold probabilities\n",
    "    example_probabilities = {}\n",
    "\n",
    "    #get denominator\n",
    "    try:\n",
    "        denominator = ngrams_started_by_wi_minus[partial_text]\n",
    "    except KeyError:\n",
    "        denominator = 0\n",
    "\n",
    "    #how much probability mass did we take away\n",
    "    #when we subtracted sigma from numerator\n",
    "    try:\n",
    "        missing_prob = sigma / ngrams_started_by_wi_minus[partial_text] * ngrams_started_by_word[partial_text]\n",
    "    except ZeroDivisionError:\n",
    "        missing_prob = 1\n",
    "\n",
    "    for i in vocab:\n",
    "\n",
    "        #initialize to 0\n",
    "        example_probabilities[i] = 0\n",
    "\n",
    "        #get numerator, if i doesn't ever\n",
    "        #come after dog set to 0\n",
    "        try:\n",
    "            numerator = ngrams_by_word[i][partial_text] - sigma\n",
    "        except KeyError:\n",
    "            numerator = 0\n",
    "\n",
    "        #first part of algorithm\n",
    "        if numerator == 0:\n",
    "            part_one = 0\n",
    "        elif denominator == 0:\n",
    "            part_one = 0\n",
    "        else:\n",
    "            part_one = numerator / denominator\n",
    "\n",
    "        #backoff part/ fertility\n",
    "        fertility = ngrams_completed_by_word[i] / len(distinct_ngrams)\n",
    "\n",
    "        example_probabilities[i] = part_one + missing_prob * fertility\n",
    "        \n",
    "    return example_probabilities\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s/>': 0.08333333333333333,\n",
       " '<s>': 0.041666666666666664,\n",
       " 'dog': 0.041666666666666664,\n",
       " 'down': 0.08333333333333333,\n",
       " 'jumped': 0.2916666666666667,\n",
       " 'ran': 0.2916666666666667,\n",
       " 'stairs': 0.041666666666666664,\n",
       " 'street': 0.041666666666666664,\n",
       " 'the': 0.08333333333333333}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dog = kneser_ney('dog')\n",
    "test_dog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check and make sure they sum to 1\n",
    "sum=0\n",
    "for i in test_dog:\n",
    "    sum += test_dog[i]\n",
    "sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<s/>': 0.16666666666666666,\n",
       " '<s>': 0.08333333333333333,\n",
       " 'dog': 0.08333333333333333,\n",
       " 'down': 0.16666666666666666,\n",
       " 'jumped': 0.08333333333333333,\n",
       " 'ran': 0.08333333333333333,\n",
       " 'stairs': 0.08333333333333333,\n",
       " 'street': 0.08333333333333333,\n",
       " 'the': 0.16666666666666666}"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now that we've bulit that let's say we\n",
    "#get some input \"The cat\" and we want\n",
    "#to predict what comes next\n",
    "test_cat = kneser_ney('cat')\n",
    "test_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check and make sure they sum to 1\n",
    "sum=0\n",
    "for i in test_cat:\n",
    "    sum += test_cat[i]\n",
    "sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
