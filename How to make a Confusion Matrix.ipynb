{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a confusion matrix  \n",
    "\n",
    "When building a classification model there are many situations where one will want to take a closer look at the predictions their model made. Specifically, the true positives, false positives, true negatives and false negative (i.e., When the true true class of the example was $X$ how often did my model predict $X$ vs. $Y,Z,...,K$). This is very useful for seeing which classes your model can easily predict and which classes are more difficult. Below is an initial example of what a confusion matrix looks like followed by a more lengthy example using real Yelp data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: libraries that are commented out are imported via preprocess.py file\n",
    "\n",
    "#import preprocess\n",
    "\n",
    "# import nltk library\n",
    "#import nltk; nltk.download('punkt')\n",
    "#from nltk import sent_tokenize\n",
    "from nltk.tokenize.treebank import TreebankWordTokenizer\n",
    "\n",
    "# import other libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import *\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import *\n",
    "\n",
    "# import helper libraries\n",
    "import collections\n",
    "from common import utils, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only restaurants \n",
    "sample_df=pd.read_csv(\"sample_review_restaurant_only.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess (based on CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very', 'pleased', 'with', 'the', 'service', '.', 'Friendly', ',', 'attentive', ',', 'and', 'fast', '.', 'I', 'had', 'vegetable', 'egg', 'rolls', 'and', 'Pad', 'Thai', '.', 'Pad', 'Thai', 'was', 'exquisite', '.', 'Not', 'too', 'oily', 'or', 'too', 'dry', ',', 'just', 'perfect', '.', 'Just', 'the', 'right', 'amount', 'of', 'food', 'on', 'the', 'plate', ',', 'the', 'tofu', 'was', 'baked', 'to', 'perfection', 'and', 'made', 'the', 'flavor', 'stand', 'out', '.', 'The', 'egg', 'rolls', 'were', 'crispy', 'but', 'not', 'over', 'fried', 'and', 'not', 'oily', 'either', '.', 'Definitely', 'coming', 'back', 'and', 'recommending', 'it', 'to', 'friends', '.']\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "\n",
    "example_text=\"\"\"Very pleased with the service. Friendly, attentive, and fast. I had vegetable egg rolls and Pad Thai. \n",
    "              Pad Thai was exquisite. Not too oily or too dry, just perfect. Just the right amount of food on the plate, \n",
    "              the tofu was baked to perfection and made the flavor stand out. The egg rolls were crispy but not over \n",
    "              fried and not oily either. Definitely coming back and recommending it to friends.\"\"\"\n",
    "\n",
    "def tokenize_text(input_text):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "    input_text: a string representing an \n",
    "    individual review\n",
    "        \n",
    "    Returns:\n",
    "    input_token: a list containing *raw* \n",
    "    tokens for an individual review\n",
    "        \n",
    "    \"\"\"\n",
    "    input_tokens=[]\n",
    "        \n",
    "    # Split sentence\n",
    "    sents=sent_tokenize(input_text)\n",
    "            \n",
    "    # Split word\n",
    "    for sent in sents:\n",
    "        input_tokens+=TreebankWordTokenizer().tokenize(sent)\n",
    "        \n",
    "    return input_tokens\n",
    "\n",
    "# example data\n",
    "input_tokens=tokenize_text(example_text)\n",
    "print(input_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['very', 'pleased', 'with', 'the', 'service', '.', 'friendly', ',', 'attentive', ',', 'and', 'fast', '.', 'i', 'had', 'vegetable', 'egg', 'rolls', 'and', 'pad', 'thai', '.', 'pad', 'thai', 'was', 'exquisite', '.', 'not', 'too', 'oily', 'or', 'too', 'dry', ',', 'just', 'perfect', '.', 'just', 'the', 'right', 'amount', 'of', 'food', 'on', 'the', 'plate', ',', 'the', 'tofu', 'was', 'baked', 'to', 'perfection', 'and', 'made', 'the', 'flavor', 'stand', 'out', '.', 'the', 'egg', 'rolls', 'were', 'crispy', 'but', 'not', 'over', 'fried', 'and', 'not', 'oily', 'either', '.', 'definitely', 'coming', 'back', 'and', 'recommending', 'it', 'to', 'friends', '.']\n"
     ]
    }
   ],
   "source": [
    "# canonicalize\n",
    "\n",
    "def canonicalize_tokens(input_tokens):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    input_tokens: a list containing *raw* \n",
    "    tokens for an individual review\n",
    "    \n",
    "    Returns:\n",
    "    input_tokens: a list containing *canonicalized* \n",
    "    tokens for an individual review\n",
    "    \n",
    "    \"\"\"\n",
    "    input_tokens=utils.canonicalize_words(input_tokens)\n",
    "    return input_tokens\n",
    "\n",
    "# example data\n",
    "canonical_tokens=canonicalize_tokens(input_tokens)\n",
    "print(canonical_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "very pleased with the service . friendly , attentive , and fast . i had vegetable egg rolls and pad thai . pad thai was exquisite . not too oily or too dry , just perfect . just the right amount of food on the plate , the tofu was baked to perfection and made the flavor stand out . the egg rolls were crispy but not over fried and not oily either . definitely coming back and recommending it to friends .\n"
     ]
    }
   ],
   "source": [
    "# preprocessor (combines tokenization, canonicalization)\n",
    "\n",
    "def preprocessor(raw_text):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    raw_text: a string representing an\n",
    "    individual review\n",
    "    \n",
    "    Returns:\n",
    "    preprocessed_text: a string representing \n",
    "    a preprocessed individual review\n",
    "    \n",
    "    \"\"\"\n",
    "    # tokenize\n",
    "    tokens=tokenize_text(raw_text)\n",
    "    \n",
    "    # canonicalize\n",
    "    canonical_tokens=canonicalize_tokens(tokens)\n",
    "    \n",
    "    # rejoin string\n",
    "    preprocessed_text=(\" \").join(canonical_tokens) \n",
    "    return preprocessed_text\n",
    "\n",
    "# example data\n",
    "preprocessed_text=preprocessor(example_text) ## punctuations left as distinct characters...\n",
    "print(preprocessed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB\n",
    "\n",
    "train Multinomial NB linear classifier to identify words with largest weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, test set size: 129023, 32256\n",
      "train, test label size: 129023, 32256\n",
      "\n",
      "example:\n",
      "text: Wings are fine, better from most of the places. Other locations-way better then this one. Just look like a fast food- not even a bar. Nice people working there, but service just not right - fun, but not right. One of the girls had a shot with customers on the next table. Not professional at all.\n",
      "label: 0\n"
     ]
    }
   ],
   "source": [
    "# get text, labels data\n",
    "text=sample_df[\"text\"].tolist() # list of strings\n",
    "labels=sample_df[\"stars\"].tolist() # list of integers\n",
    "\n",
    "# recode labels (combine ratings 1,2 and 4,5)\n",
    "def recode(x):\n",
    "    if x==1 or x==2 or x==3: x=0 # includes ratings 1,2 & 3\n",
    "    else: x=1 # includes ratings 4,5\n",
    "#     else: x=1 # includes only rating 3    \n",
    "    return x\n",
    "\n",
    "recoded_labels=list(map(recode, labels))\n",
    "\n",
    "# using recoded labels\n",
    "train_data, test_data, train_labels, test_labels=train_test_split(text, recoded_labels, test_size=.2)\n",
    "\n",
    "# examine train, test shapes\n",
    "print(\"train, test set size: %d, %d\" %(len(train_data), len(test_data))) # train_data: 129023, test_data: 32256\n",
    "print(\"train, test label size: %d, %d\" %(len(train_labels), len(test_labels)))\n",
    "print(\"\")\n",
    "\n",
    "# examine train set examples\n",
    "print(\"example:\")\n",
    "print(\"text: %s\" %(train_data[1]))\n",
    "print(\"label: %d\" %(train_labels[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 56256, 1: 105023})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collections.Counter(recoded_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary size: 92672\n",
      "multinomial nb f1 score: 0.794\n",
      "multinomical nb accuracy score: 0.799\n"
     ]
    }
   ],
   "source": [
    "# countvectorizer\n",
    "stop_words=[\"that\", \"in\", \"we\", \"for\", \"of\", \"it\", \"was\", \"to\", \"and\", \"the\", \"but\", \"is\", \"with\", \"i\", \"you\"]\n",
    "vec=CountVectorizer(preprocessor=preprocessor, stop_words=stop_words)\n",
    "vec_train_data=vec.fit_transform(train_data) \n",
    "vec_test_data=vec.transform(test_data) \n",
    "print(\"vocabulary size: %d\" %(vec_train_data.shape[1]))\n",
    "\n",
    "# train model (no hyperparameter tuning)\n",
    "mnb=MultinomialNB()\n",
    "mnb.fit(vec_train_data, train_labels)\n",
    "pred_labels=mnb.predict(vec_test_data)\n",
    "    \n",
    "# assess model\n",
    "f1=f1_score(test_labels, pred_labels, average=\"weighted\") \n",
    "accuracy=accuracy_score(test_labels, pred_labels)\n",
    "print(\"multinomial nb f1 score: %.3f\" %(f1))\n",
    "print(\"multinomical nb accuracy score: %.3f\" %(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted Rating</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Rating</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5009</td>\n",
       "      <td>1160</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>958</td>\n",
       "      <td>1661</td>\n",
       "      <td>1880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>827</td>\n",
       "      <td>1058</td>\n",
       "      <td>19106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted Rating     0     1      2\n",
       "Actual Rating                      \n",
       "0                 5009  1160    597\n",
       "1                  958  1661   1880\n",
       "2                  827  1058  19106"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create confusion matrix\n",
    "pd.crosstab(test_labels, pred_labels, rownames=['Actual Rating'], colnames=['Predicted Rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating category 1\n",
      "at -4.81\n",
      "DG -4.76\n",
      "had -4.75\n",
      "on -4.69\n",
      "were -4.66\n",
      "food -4.62\n",
      "they -4.55\n",
      "this -4.48\n",
      "my -4.47\n",
      "not -4.44\n",
      "\n",
      "rating category 2\n",
      "had -4.84\n",
      "DG -4.74\n",
      "were -4.72\n",
      "this -4.71\n",
      "food -4.7\n",
      "they -4.67\n",
      "good -4.66\n",
      "on -4.65\n",
      "my -4.63\n",
      "not -4.57\n",
      "\n",
      "rating category 3\n",
      "great -4.82\n",
      "place -4.81\n",
      "have -4.78\n",
      "good -4.73\n",
      "had -4.73\n",
      "on -4.66\n",
      "they -4.65\n",
      "food -4.64\n",
      "my -4.51\n",
      "this -4.47\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# examine features w/ greatest weights\n",
    "\n",
    "def top_features(coefs, num_feats):\n",
    "    \"\"\"\n",
    "    Args: \n",
    "    coefs: array of shape (num_labels, vocab_size)\n",
    "    num_feats: number of top features\n",
    "    \n",
    "    Prints:\n",
    "    top num_feats features with great weights by\n",
    "    rating category\n",
    "    \n",
    "    \"\"\"   \n",
    "    # identify top coefs per rating category\n",
    "    top_indices=np.argsort(coefs, axis=1)[:,-num_feats:] # (num_labels, num_feats) \n",
    "    \n",
    "    # display feature, weight\n",
    "    for r in range(top_indices.shape[0]):\n",
    "        print(\"rating category %d\" %(r+1))\n",
    "        for c in range(top_indices.shape[1]):\n",
    "            feat=vec.get_feature_names()[top_indices[r,c]]\n",
    "            weight=round(coefs[r, top_indices[r,c]], 2)\n",
    "            print(feat, weight)\n",
    "        print(\"\")\n",
    "\n",
    "top_features(mnb.coef_, num_feats=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
